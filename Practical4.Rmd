---
title: "Kaminda - Practical 4"
output: html_notebook
---

```{r}
install.packages("xgboost")
install.packages("eegkit")
install.packages("forecast")
install.packages("tseries")
install.packages("caret")
```

```{r}
library(xgboost)
library(eegkit)
library(forecast)
library(tseries)
library(caret)
```

```{r}
library(dplyr)
library(reshape2)
library(purrr)
library(ggplot2)
```

```{r parse_data}
eeg_url <- "https://h2o-public-test-data.s3.amazonaws.com/smalldata/eeg/eeg_eyestate_splits.csv"
eeg_data <- read.csv(eeg_url)

# Adding timestamp
Fs <- 117 / nrow(eeg_data)
eeg_data <- transform(eeg_data, ds = seq(0, 116.99999, by = Fs), eyeDetection = as.factor(eyeDetection))
print(table(eeg_data$eyeDetection))

# Splitting dataset into train, validate, test
eeg_train <- subset(eeg_data, split == 'train', select = -split)
print(table(eeg_train$eyeDetection))

eeg_validate <- subset(eeg_data, split == 'valid', select = -split)
eeg_test <- subset(eeg_data, split == 'test', select = -split)
```

**0**


```{r}
num_samples <- nrow(eeg_data)
duration <- 117  # In seconds
samples_per_second <- num_samples / duration

samples_per_second

```

# Approximately 128 samples per second were taken.

**1**

```{r}
num_electrodes <- ncol(eeg_data)

num_electrodes

```

# there were 17 sensors used.

### Exploratory Data Analysis

```{r check_na}
sum(is.na(eeg_data))
```

```{r plot data}
melt <- reshape2::melt(eeg_data %>% dplyr::select(-split), id.vars=c("eyeDetection", "ds"), variable.name = "Electrode", value.name = "microvolts")


ggplot2::ggplot(melt, ggplot2::aes(x=ds, y=microvolts, color=Electrode)) + 
  ggplot2::geom_line() + 
  ggplot2::ylim(3500,5000) + 
  ggplot2::geom_vline(ggplot2::aes(xintercept=ds), data=dplyr::filter(melt, eyeDetection==1), alpha=0.005)
```

**2**

# The EEG appears to be more intense in the periods right before the eyes open and right before they close.

**3**

# I anticipate that there will be similar correlation; that in the time right before and after opening, the EEG will be most intense, and in the time when eyes are closed, the EEG will be the least intense.

```{r compare_distrib}
melt_train <- reshape2::melt(eeg_train, id.vars=c("eyeDetection", "ds"), variable.name = "Electrode", value.name = "microvolts")

# filter huge outliers in voltage
filt_melt_train <- dplyr::filter(melt_train, microvolts %in% (3750:5000)) %>% dplyr::mutate(eyeDetection=as.factor(eyeDetection))

ggplot2::ggplot(filt_melt_train, ggplot2::aes(y=Electrode, x=microvolts, fill=eyeDetection)) + ggplot2::geom_boxplot()
```

```{r compare_summary_stats}
filt_melt_train %>% dplyr::group_by(eyeDetection, Electrode) %>% 
    dplyr::summarise(mean = mean(microvolts), median=median(microvolts), sd=sd(microvolts)) %>% 
    dplyr::arrange(Electrode)
```

**4**

# Based on these analyses, electrodes F8, O2, and P7 are consistently more intense than the others.

### Time-Related Trends

```{r convert_to_tseries}
apply(eeg_train, 2, tseries::adf.test)
```

**5**

# Stationarity refers to the statistical properties of a time-series not changing over time. A stationary time-series will have a constant mean and variance, and will generally exhibit a linear function.

**6**

# We are interested in stationarity

```{r correlation}
forecast::ggAcf(eeg_train %>% dplyr::select(-ds))
```

**7**

# The fields that show signs of strong autocorrelation are F7, FC5, FC6, and F4.

###Frequency-Space

```{r fft_open}
eegkit::eegpsd(eeg_train %>% dplyr::filter(eyeDetection == 0) %>% dplyr::select(-eyeDetection, -ds), Fs = Fs, xlab="Eye Open")
```

```{r fft_closed}
eegkit::eegpsd(eeg_train %>% dplyr::filter(eyeDetection == 1) %>% dplyr::select(-eyeDetection, -ds), Fs = Fs, xlab="Eye Closed")
```

**8**

# There are differences...

###Independent Component Analysis

```{r ica, warning=FALSE}
ica <- eegkit::eegica(eeg_train %>% dplyr::select(-eyeDetection, -ds), nc=3, method='fast', type='time')
mix <- dplyr::as_tibble(ica$M)
mix$eyeDetection <- eeg_train$eyeDetection
mix$ds <- eeg_train$ds

mix_melt <- reshape2::melt(mix, id.vars=c("eyeDetection", "ds"), variable.name = "Independent Component", value.name = "M")


ggplot2::ggplot(mix_melt, ggplot2::aes(x=ds, y=M, color=`Independent Component`)) + 
  ggplot2::geom_line() + 
  ggplot2::geom_vline(ggplot2::aes(xintercept=ds), data=dplyr::filter(mix_melt, eyeDetection==1), alpha=0.005) +
  ggplot2::scale_y_log10()
```

**9**

# Yes, this ICA suggests that eye opening relates to an independent component of activity across the electrodes.

###Eye Opening Prediction

```{r xgboost}
# Convert the training and validation datasets to matrices
eeg_train_matrix <- as.matrix(dplyr::select(eeg_train, -eyeDetection, -ds))
eeg_train_labels <- as.numeric(eeg_train$eyeDetection) -1

eeg_validate_matrix <- as.matrix(dplyr::select(eeg_validate, -eyeDetection, -ds))
eeg_validate_labels <- as.numeric(eeg_validate$eyeDetection) -1

# Build the xgboost model
model_xgboost <- xgboost(data = eeg_train_matrix, 
                 label = eeg_train_labels,
                 nrounds = 100,
                 max_depth = 4,
                 eta = 0.1,
                 objective = "binary:logistic")

print(model)
```

```{r XGBOOST evaluation}
# Assuming you have chosen XGBoost as the model to evaluate

# Make predictions on the validation data using the XGBoost model
xgboost_pred <- predict(model_xgboost, eeg_validate_matrix)

# Convert the predicted values to binary predictions (0 or 1)
xgboost_pred_binary <- ifelse(xgboost_pred > 0.5, 1, 0)

# Compute accuracy on the validation data
validation_accuracy <- mean(xgboost_pred_binary == eeg_validate_labels)

# Print the validation accuracy
cat("Validation Accuracy:", validation_accuracy, "\n")
```

**10**


```{r}
library(caret)
```

```{r model2 nnet}

#Converting training and validation datasets to matrices
eeg_train_matrix <- as.matrix(dplyr::select(eeg_train, -eyeDetection, -ds))
eeg_train_labels <- as.numeric(eeg_train$eyeDetection) -1

eeg_validate_matrix <- as.matrix(dplyr::select(eeg_validate, -eyeDetection, -ds))
eeg_validate_labels <- as.numeric(eeg_validate$eyeDetection) -1

#Defining training control
train_control <- trainControl(
  method = "cv",  # Cross-validation
  number = 5,     # Number of folds
  verboseIter = TRUE
)

# Defining the Neural Network model
model_nnt <- train(
  x = eeg_train_matrix, 
  y = eeg_train_labels,
  method = "nnet",        # Neural Network algorithm
  trControl = train_control
)

# Printing the model
print(model)

```

```{r nnet evaluation}

# Making predictions on the validation data using the Neural Network model
nnet_pred <- predict(model_nnt, eeg_validate_matrix)

# Converting the predicted values to binary predictions (0 or 1)
nnet_pred_binary <- ifelse(nnet_pred > 0.5, 1, 0)

# Computing accuracy on the validation data
validation_accuracy <- mean(nnet_pred_binary == eeg_validate_labels)

# Printing the validation accuracy
cat("Validation Accuracy:", validation_accuracy, "\n")

```

**11**

```{r test accuracy}

# Make predictions on the test data using the XGBoost model
test_pred <- predict(model_xgboost, )

# Convert the predicted values to binary predictions (0 or 1)
test_pred_binary <- ifelse(test_pred > 0.5, 1, 0)

# Compute accuracy on the test data
test_accuracy <- mean(test_pred_binary == eeg_test_labels)

# Print the test accuracy
cat("Test Accuracy:", test_accuracy, "\n")

```


```{r}
# Making predictions on the test data using the XGBoost model
test_pred <- predict(model, eeg_test_matrix)

# Converting the predicted values to binary predictions (0 or 1)
test_pred_binary <- ifelse(test_pred > 0.5, 1, 0)

# Computing accuracy on the test data
test_accuracy <- mean(test_pred_binary == eeg_test_labels)

# Printing the test accuracy
cat("Test Accuracy:", test_accuracy, "\n")

```

**12**
# We can also model eye opening predictions from EEG's using the frequency domain or the state space domain.

# With the frequency domain, we can use the Laplace methods.

# With the state space domain, we can use the Hidden Markov models.

**13**

# To use the Laplace methods, I can load the "Laplace" package.

```{r}
#Installing package
install.packages("Laplace")
```

# To use the Hidden Markov models, I can load the "RHmm" package.

```{r}
#Installing package
install.packages("RHmm")
```

**14**

# To help with the completion of the labs, I would have appreciated an additional online/in person "lab" scheduled on another day to get support with R.

# The main takeaway for me from this course was the various methods for data analysis and machine learning different types of data in R. The main reason I took this course was so I could become more familiar with R.

# Overall, I really enjoyed this course and it opened my eyes to the various applications of machine learning of health. Especially regarding potential careers or further study. Thank you for a great term Dr. Maguire!